{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "qifqfg25mv",
   "metadata": {},
   "source": [
    "# Optimus Prime - MD5 Hash Inversion Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a3c0b5",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4d5d95",
   "metadata": {},
   "source": [
    "```\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣶⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢰⠀⠀⠀⠀⠀⣤⣤⣤⠀⠀⠀⠀⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡇⠀⣠⡶⢿⡇⢿⣿⡏⢳⣦⠀⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣾⡛⣆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣧⣼⣿⣴⣋⡽⠮⠿⢭⣟⣏⣷⣿⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢻⣧⠘⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡼⣇⣿⡿⠶⣶⣿⣟⡛⣷⣿⢠⠙⣧⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣀⡈⣏⠇⢹⡀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡟⢹⠁⣿⠋⠉⢹⠉⠙⣿⡇⣾⣀⣾⠀⢀⣤⡀⢀⡀⠀⠀⢀⣠⣴⣾⠛⢻⡛⢻⡄⢀⣳⡀⢀⣠⠄⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣾⣷⣾⢀⣿⡇⠀⠸⠀⠀⣿⣧⡽⠿⣟⣺⣭⠴⢿⡏⣩⣷⡾⢛⣭⣴⣿⣇⠘⣿⣷⣿⡛⠉⢻⣟⣷⠄⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠿⢿⣟⣿⣿⡦⣶⣪⡭⠿⣚⣫⣭⣽⣶⡄⠀⢸⡇⣿⡙⣿⣿⣿⣿⣿⣿⣆⠹⣿⣿⣷⡀⠀⢿⡉⠁⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣀⣀⣤⣶⣿⠿⠛⣉⣭⣶⣾⣿⠿⠟⠛⠉⠉⢻⠀⢸⣷⣿⣇⢻⡿⣿⣿⣿⣿⠟⠀⠹⣿⣿⠃⠀⠘⣷⡀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣤⣦⣼⣿⠿⠛⣋⡁⣼⢠⣿⡿⠛⠉⠁⠀⠀⢀⡀⢀⣴⣾⠀⢸⣿⡇⢻⡄⠙⠿⠻⠛⠁⠀⢀⣠⣽⣿⣇⡀⠀⠸⣧⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⣾⠿⣛⣭⣴⡾⠟⠛⣧⣿⢸⡿⠀⠀⠀⠀⣰⣿⣿⣷⣾⣿⣿⠀⢸⡏⣇⢸⣷⡀⠀⢀⣠⣴⣾⠿⠛⣿⢻⣿⣹⡀⠀⢻⣆⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣴⡟⣦⠀⠀⠀⢀⡿⣵⡿⠛⠉⣡⣶⣤⣄⣿⣯⢸⣇⠀⠀⢠⣾⣿⡿⣿⣿⣿⣿⡿⠀⢸⡇⢻⡼⣿⣷⣶⠿⠛⠉⠀⠀⠀⠸⡇⣿⣿⣧⠀⠘⣿⡀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⡇⢹⠀⢀⣠⣼⣿⣿⠀⢀⣼⣿⣿⣿⣿⡇⣿⢸⣿⣀⣀⣿⡿⠿⠶⠚⠛⠉⠉⠀⠀⢸⡇⠀⢻⣾⣝⣿⡆⠀⢀⣠⡴⠖⠛⢻⡾⣿⣿⣆⠀⢹⡇⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣇⣼⡾⠟⠋⣿⢻⣇⣤⣌⠻⢿⣿⣿⣿⠃⢿⠀⠉⠉⠁⠀⠀⠀⣀⣤⡤⠶⠶⠒⠚⣻⣷⣄⠈⣿⣿⣿⣿⡞⠉⠀⠀⠀⠀⠀⣿⢿⣿⣾⣋⣽⠇⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣹⠏⠀⠀⠀⣿⢿⣿⣿⣯⡴⠾⠛⢋⣡⠶⠛⠛⠋⣉⣉⣉⣙⢻⣿⠀⠀⠀⠀⠀⢠⡟⠀⠈⠻⢦⣈⣿⣿⣧⠀⠀⢀⣠⣴⡾⢿⣿⣿⣿⣿⣿⡀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⡟⣿⡟⠀⠀⠀⣿⠈⠋⠉⢀⣠⠴⣛⣩⣤⣶⣞⣭⣿⢿⣿⣿⣻⣼⣿⣆⣀⣤⣤⣴⣿⣄⣠⣶⣦⣀⣙⣿⣿⣿⡶⣿⠟⠋⣁⣶⠟⢻⣽⣿⣿⣿⠇⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⢠⣿⣇⠀⠀⠀⢹⣠⡴⠖⢻⣷⢫⣿⣿⣿⣯⣿⣟⣿⣿⣭⣽⣿⡿⣿⣿⣿⠿⠿⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⣿⠋⠉⣿⠀⢸⣿⣿⣿⣿⣷⡀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣼⣿⣿⣤⣴⣾⢿⡅⠀⣀⣾⢿⣿⣿⣿⣿⣿⣿⡿⣿⣷⣿⣿⣿⡇⣿⣿⡇⠀⠀⢸⣿⣿⡟⢿⣿⣿⣿⣿⣿⣣⣿⠁⣿⣀⣤⡿⠀⢀⣿⣿⣿⣿⣿⡇⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡇⠻⣿⠛⠉⠀⠈⣿⠛⢽⣿⢻⣿⣿⢿⣿⣿⣿⡇⣿⠿⣶⣶⣚⣧⣿⣿⡇⠀⠀⣸⣿⣿⣿⣄⣈⢿⣿⢿⣷⣿⣿⠀⠉⠉⠀⠀⠀⠘⡇⣿⣿⣿⣿⡇⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡇⡀⣷⡆⠀⠀⠀⠸⣧⣻⣿⢸⣿⣿⡿⢿⣾⣻⡇⣿⣿⣿⣿⣿⣿⣿⠿⠷⠾⠛⠛⠿⢿⣿⣿⣿⣄⣿⠿⠋⢸⣿⠀⠀⠀⠀⠀⠀⠀⡇⣿⣿⣿⣿⣿⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣷⡇⣿⡇⠀⠀⠀⠀⣿⣿⣿⡾⢿⣿⣿⣿⣿⡶⠷⠾⠛⠛⠉⠁⢀⣠⠤⠴⠒⡆⢠⠀⢰⡉⠻⣿⣽⡏⠀⠀⢸⡇⠀⠀⠀⠀⠀⠀⠀⡇⣿⡿⣿⣿⣿⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣧⣿⠿⢀⣀⣤⣴⣿⣿⣿⡷⠾⠛⠋⠉⢀⣀⣠⠤⠴⠒⠻⡆⢸⠀⠀⢀⡠⠇⠸⡄⠈⣇⠀⠈⡻⢦⡀⠀⢸⡇⠀⠀⠀⠀⠀⠀⠀⡇⣿⣧⡘⠿⢻⡆\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠻⣆⣿⣿⣿⣿⣿⡿⠛⣉⣀⡀⣠⠴⠒⠋⠉⠁⠀⠀⠀⠀⠀⡇⢸⣠⠴⣫⡄⠀⠀⡇⠀⢹⠀⠀⣿⠦⢿⡀⢸⡇⠀⠀⣀⣤⣤⣿⠀⡇⣿⣿⣿⣆⢸⡇\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣿⢿⡟⣽⣿⠀⣏⠁⠀⡇⡟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣇⠀⡖⣻⠋⠀⠀⠈⢻⠀⢈⡇⠀⠸⡄⠘⣧⢸⡇⠀⢸⣷⣾⣿⠏⠀⡇⣿⣿⣿⣿⢸⡇\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣾⠏⠛⠋⢡⣿⠀⠸⣿⣟⡃⣇⠀⠀⠀⠀⠀⣀⣠⡤⠶⠒⠋⠀⠛⠁⠀⣀⣤⣶⣿⣿⣿⣿⣷⣤⡈⠁⢻⡞⣿⠀⠈⠻⣴⠏⠀⠀⠿⢹⣿⣎⢻⣿⡇\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣾⡟⠀⠀⢀⡿⣿⠀⠀⠈⠳⡇⠻⠤⠶⠚⠋⠉⠁⠀⠀⠀⠀⠀⣀⣤⣶⣿⣿⣿⣿⣿⠿⠛⠻⣿⣿⣿⣷⣜⣷⣿⠀⠀⢀⣀⣤⣤⣶⣾⣶⣿⣿⠃⢸⡇\n",
    "⠀⠀⠀⠀⠀⠀⣀⣤⡶⠶⠖⠚⢛⠛⠳⢶⣼⡟⠀⠀⢀⣼⣹⣿⢀⠀⠀⠀⠀⡀⠀⠀⠀⠀⠀⢀⣀⣠⡤⢤⣾⣿⣿⣿⡿⠿⠛⠉⠹⡇⠀⠀⣿⣿⣟⢿⣿⣿⠹⣶⣿⡿⠛⠻⣏⠀⠉⠉⡛⣿⡿⣾⡇\n",
    "⠀⠀⠀⢀⣴⠞⠋⢰⡇⢰⣿⢻⢻⢻⢶⣦⠙⣷⡀⠀⣸⢧⠟⢿⣿⣿⣿⣷⣶⣶⣤⣴⣲⡾⠿⠟⠒⠒⠛⡇⠙⣿⠉⠀⢧⠀⠀⠀⠀⣧⠀⠀⢸⣿⣿⡎⣿⠁⢀⣼⣏⢀⣠⣤⣸⣶⠀⠀⣿⣿⣿⠛⠁\n",
    "⠀⠀⠀⣾⠃⠀⣠⡬⣤⣼⣛⠾⣼⣞⡾⡟⠀⠘⣧⣠⣏⡞⠀⠈⠻⣿⡏⢹⡟⠛⠻⣿⠁⠀⠀⠀⠀⠀⠀⣇⠀⣿⠀⠀⢸⡄⠀⠀⠀⢸⠀⠀⠘⣿⣿⣇⣿⣴⡞⢣⣽⣿⣿⣿⣿⣿⠀⠀⣿⣿⡟⠀⠀\n",
    "⠀⠀⠀⣿⡶⣿⣿⣸⣿⣿⣿⠿⠷⠾⢽⣅⡲⠶⢻⣿⣼⢁⣠⣤⣶⣿⣿⠘⡇⠀⠀⢻⡆⠀⠀⠀⠀⠀⢀⣸⡀⢹⡇⠀⠈⡇⠀⠀⠀⠈⡇⠀⠀⢿⣿⣿⢹⣿⣤⣿⣿⣿⣿⡿⢿⣟⡀⠀⣿⣿⡇⠀⠀\n",
    "⠀⠀⠀⠈⠛⠿⢯⣜⣿⠏⠀⠀⠀⢀⡿⣨⣿⣶⣤⣿⣷⣯⣿⣿⣿⣿⣿⠀⡇⠀⠀⠐⡿⣦⣰⣒⣶⣿⣿⣿⣷⣾⣇⠀⠀⢻⠀⠀⠀⠀⢷⠀⠀⢸⣿⣿⣾⣿⣸⣿⡏⢠⠟⣠⣿⣿⣿⣦⡈⢹⡇⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⢸⡟⣾⠄⠀⠀⣸⡇⣿⣿⣿⠟⠋⠛⢿⣿⣿⣿⣿⣿⡄⢻⠀⠀⠀⡇⠈⠙⣿⣿⣿⣿⣿⣿⣿⣿⠀⠀⢸⡆⠀⠀⠀⢸⡄⠀⠀⣿⣿⣇⣿⠛⠛⠻⣿⣺⣿⣿⣿⣿⣿⣿⡿⠃⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⣼⢧⡇⠀⠀⠀⣿⢸⣿⣿⡿⢦⣴⣿⣿⣷⡿⣿⡿⣿⡇⢸⡄⠀⠀⢹⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⡆⠀⠀⣇⠀⠀⠀⠀⣇⠀⠀⢸⣿⣟⢿⡀⠀⠀⠈⠉⠀⠉⠉⠉⠁⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⣿⣨⡧⠤⠤⢤⣇⡾⣿⣿⣠⣿⣿⣿⣿⣿⣿⣽⣿⣿⣷⠀⣇⠀⠀⢸⠀⠀⢸⢻⣿⣿⣿⣿⡇⣿⣿⠀⠀⢹⡄⠀⠀⢀⣸⠀⠀⠸⣿⣿⣼⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⢀⡿⣧⣤⠶⠦⣼⣿⣿⣿⡏⠈⣿⣿⢿⣿⣿⣿⣏⠉⢹⣿⡀⢻⠀⠀⠘⡇⠀⠸⡄⠙⢿⣿⣿⠇⣿⣿⡄⠀⠈⠓⠒⠋⠉⠀⠀⠀⠀⢿⠹⣯⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⣸⣿⢃⡏⠀⠀⢻⣿⣿⣽⣿⣦⠘⣿⣿⣿⣿⣿⢻⣿⣾⣿⡇⠘⡇⠀⠀⣇⠀⠀⣇⠀⠀⠙⢿⡇⣿⢸⣧⠀⠀⠀⠀⡴⠒⢶⠀⠀⠀⠘⣆⠀⢻⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⡿⡅⣸⢁⣄⡄⣾⣿⢿⣿⠿⣿⣿⢻⣿⣿⣟⣿⣸⣻⡿⣿⣧⠀⠙⠒⠛⠛⠀⠀⢿⣿⣄⠀⠀⠀⣿⠈⣿⡄⠀⠀⠀⡇⠀⠘⡇⠀⠀⠀⢿⣦⢸⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⢸⣧⡇⣿⣼⣿⠃⣿⣿⣾⣿⣷⣤⡿⠿⢿⣿⣿⣇⣿⡟⠋⠀⣿⡀⠀⣴⠲⡆⠀⠀⠸⣿⣿⣦⠀⠀⢸⡀⢹⣧⠀⠀⠀⣇⠀⠀⢹⠀⠀⠀⠸⣿⡟⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀  ⢽⡿⣷⠏⠛⠿⢠⣿⣿⣿⣿⢿⣯⡇⠀⠀⠈⠁⠀⠀⠀⠀⠀⢸⣇⠀⢻⠀⢳⠀⠀⠀⣿⣿⣿⣷⣾⢸⡇⠈⣿⡀⠀⠀⢸⠀⠀⠈⡇⠀⠀⢀⣿⣿⣷⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "            ____        __  _                         ____       _              ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "           / __ \\____  / /_(_)___ ___  __  _______   / __ \\_____(_)___ ___  ___ ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "          / / / / __ \\/ __/ / __ `__ \\/ / / / ___/  / /_/ / ___/ / __ `__ \\/ _ \\⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "         / /_/ / /_/ / /_/ / / / / / / /_/ (__  )  / ____/ /  / / / / / / /  __/⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "         \\____/ .___/\\__/_/_/ /_/ /_/\\__,_/____/  /_/   /_/  /_/_/ /_/ /_/\\___/ ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "             /_/                                                                 ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "```\n",
    "\n",
    "\n",
    "This notebook trains the **OptimusPrime** transformer model to learn mappings from MD5 hash digests to plaintext passwords.\n",
    "\n",
    "- **Model**: Transformer encoder-decoder architecture\n",
    "- **Task**: Sequence-to-sequence learning (hash → password)\n",
    "- **Dataset**: 1M hash-password pairs\n",
    "- **Features**: TensorBoard logging, checkpoint saving/loading, evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sbdkvic8jos",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "\n",
    "Import all necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b54b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "# local\n",
    "from model import OptimusPrime\n",
    "from optimizer import AdamWarlock\n",
    "from data import Bumblebee, collate_batch, ALLOWED_PW_CHARS as PW_VOCAB, PAD_ID, SOS_ID, EOS_ID\n",
    "from trainer import Trainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emfbm9qg5iu",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4271af9",
   "metadata": {},
   "source": [
    "`Hyperparameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90183745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "EPOCHS = 10\n",
    "TRAIN_BATCH_SIZE = 1024\n",
    "EVAL_BATCH_SIZE = ...\n",
    "LR = 1e-4\n",
    "\n",
    "# trainer\n",
    "WEIGHT_LOAD_MODE = 'latest'  # 'best', 'latest', or 'none'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# eval\n",
    "EVAL_TEMPERATURE = 1.0\n",
    "REPITION_PENALTY = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2de5b3",
   "metadata": {},
   "source": [
    "`Datasets & Dataloaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4211e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "TRAIN_DATA_PATH = Path.cwd().parent / 'data' / 'training' / '1M_train.tsv'\n",
    "EVAL_DATA_PATH = Path.cwd().parent / 'data' / 'eval' / '1K_eval.tsv'\n",
    "\n",
    "# datasets\n",
    "TRAIN_DATA = Bumblebee(TRAIN_DATA_PATH)\n",
    "EVAL_DATA = Bumblebee(EVAL_DATA_PATH)   # optional: for automatic eval during training\n",
    "\n",
    "# dataloaders\n",
    "t_dataloader = DataLoader(TRAIN_DATA, batch_size = TRAIN_BATCH_SIZE, shuffle = True, collate_fn = collate_batch)\n",
    "e_dataloader = DataLoader(EVAL_DATA, batch_size = 128 or EVAL_BATCH_SIZE, collate_fn = collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93675cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dataset size]: 996,035 samples\n",
      "[batches per epoch]: 973\n"
     ]
    }
   ],
   "source": [
    "print(f'[dataset size]: {len(TRAIN_DATA):,} samples')\n",
    "print(f'[batches per epoch]: {len(t_dataloader):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d0f48a",
   "metadata": {},
   "source": [
    "## 3. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73742c6",
   "metadata": {},
   "source": [
    "`OptimusPrime`  \n",
    "transformer encoder-decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "xjlz4r9te6h",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = OptimusPrime(\n",
    "    vocab_size = 256,\n",
    "    pw_vocab_size = len(PW_VOCAB),\n",
    "    pad_id = PAD_ID,\n",
    "    sos_id = SOS_ID,\n",
    "    eos_id = EOS_ID,\n",
    "    d_model = 256,\n",
    "    n_heads = 8,\n",
    "    num_layers = 4,\n",
    "    ff_dim = 512,\n",
    "    dropout = 0.1,\n",
    "    label_smoothing = 0.00     # prevent overconfidence (0.1-0.2 recommended)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a1bae93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 5,902,413\n",
      "Trainable parameters: 5,902,413\n"
     ]
    }
   ],
   "source": [
    "# count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'Total parameters: {total_params:,}')\n",
    "print(f'Trainable parameters: {trainable_params:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b852a5",
   "metadata": {},
   "source": [
    "`AdamWarlock`  \n",
    "AdamW optimizer wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "p2a9iljec9p",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[35m[ADAM WARLOCK INIT]\u001b[0m\n",
      "  [base learning rate]: 1.00e-04\n",
      "  [weight decay]: 0.01\n",
      "  [betas]: (0.9, 0.999)\n",
      "  [scheduler]: cosine annealing decay\n",
      "  [total steps]: 9,730\n",
      "  [warmup steps]: 1,000\n",
      "  [decay steps]: 8,730\n",
      "  [schedule]: warmup → cosine decay\n"
     ]
    }
   ],
   "source": [
    "# create optimizer with scheduling\n",
    "total_steps = EPOCHS * len(t_dataloader)\n",
    "\n",
    "optimizer = AdamWarlock(\n",
    "    model.parameters(),\n",
    "    lr = LR,\n",
    "    weight_decay = 0.01,\n",
    "    warmup_steps = 1000,\n",
    "    total_steps = total_steps,\n",
    "    use_cosine_decay = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf8c9d",
   "metadata": {},
   "source": [
    "`Trainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9n1uqtuu54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [\u001b[34mTRAINER INIT\u001b[0m]\n",
      "  [init TensorBoard]\n"
     ]
    }
   ],
   "source": [
    "# create trainer\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    dataloader = t_dataloader,      # TRAINING dataloader\n",
    "    eval_dataloader = e_dataloader, # EVAL dataloader; enables automatic eval every 10 epochs\n",
    "    device = DEVICE,\n",
    "    epochs = EPOCHS,\n",
    "    checkpoint_dir = Path('checkpoints'),\n",
    "    checkpoint_interval = 1,\n",
    "    logs = 'runs/optimus',\n",
    "    keep = True,\n",
    "    load_mode = WEIGHT_LOAD_MODE,\n",
    "    eval_checkpoint = 3,\n",
    "    max_checkpoints = 5,            # keep only 5 most recent checkpoints\n",
    "    temperature = EVAL_TEMPERATURE,\n",
    "    repetition_penalty = REPITION_PENALTY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uew222q9yi",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27831869",
   "metadata": {},
   "source": [
    "Run full training loop with gradient tracking, TensorBoard logging, and checkpoint saving.  \n",
    ">**NOTE**: If `eval_dataloader` was provided to the Trainer, evaluation will run automatically every 10 epochs during training, saving predictions to `predictions_ep_{N}.tsv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mkk6ugdczyn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33m [NO CHECKPOINT FOUND]\u001b[0m\n",
      "  [load_mode]: latest\n",
      "  [starting fresh training]\n",
      "\n",
      "\u001b[34m [START]\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 973/973 [03:28<00:00,  4.66 batch/s, loss=3.0837, grad=0.441, lr=9.73e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [epoch 1 / 10 complete]\n",
      "  [loss]: 3.0837\n",
      "  [time]: 3.48 minutes\n",
      "    [\u001b[32mnew best saved\u001b[0m]: inf -> 3.0837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:   3%|▎         | 26/973 [00:05<03:25,  4.62 batch/s, loss=2.6308, grad=0.415, lr=9.99e-05]/home/laufeyson/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:198: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Epoch 2/10: 100%|██████████| 973/973 [03:28<00:00,  4.66 batch/s, loss=2.5702, grad=0.428, lr=9.71e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [epoch 2 / 10 complete]\n",
      "  [loss]: 2.5702\n",
      "  [time]: 3.48 minutes\n",
      "    [\u001b[32mnew best saved\u001b[0m]: 3.0837 -> 2.5702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 973/973 [03:30<00:00,  4.61 batch/s, loss=2.4909, grad=0.437, lr=8.85e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [epoch 3 / 10 complete]\n",
      "  [loss]: 2.4909\n",
      "  [time]: 3.52 minutes\n",
      "    [\u001b[32mnew best saved\u001b[0m]: 2.5702 -> 2.4909\n",
      "\n",
      "\u001b[36m [STARTING EVALUATION at epoch 3]\u001b[0m\n",
      "\n",
      "\u001b[34m [EVALUATION]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:01<00:00,  4.65 batch/s, loss = 2.7507, exact = 0.0000, char = 0.0348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 973/973 [03:25<00:00,  4.73 batch/s, loss=2.4463, grad=0.417, lr=7.53e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [epoch 4 / 10 complete]\n",
      "  [loss]: 2.4463\n",
      "  [time]: 3.43 minutes\n",
      "    [\u001b[32mnew best saved\u001b[0m]: 2.4909 -> 2.4463\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 973/973 [03:25<00:00,  4.73 batch/s, loss=2.4170, grad=0.412, lr=5.89e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [epoch 5 / 10 complete]\n",
      "  [loss]: 2.4170\n",
      "  [time]: 3.43 minutes\n",
      "    [\u001b[32mnew best saved\u001b[0m]: 2.4463 -> 2.4170\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  23%|██▎       | 221/973 [00:46<02:44,  4.57 batch/s, loss=2.4010, grad=0.423, lr=5.50e-05]"
     ]
    }
   ],
   "source": [
    "# setup trainer / load weights\n",
    "trainer.load()\n",
    "\n",
    "# train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8vs9tp4nv8e",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "Evaluate the trained model on a held-out test set with multiple similarity metrics:\n",
    "- **Exact Match**: Perfect character-by-character match\n",
    "- **Char Similarity**: Positional character matching\n",
    "- **Levenshtein**: Normalized edit distance\n",
    "- **Jaccard**: Character set overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef780d85",
   "metadata": {},
   "source": [
    "Results __are__ logged to TensorBoard under the `Eval/` namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lso8lej4t",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "# Note: eval already ran automatically every 10 epochs during training if eval_dataloader was provided to Trainer\n",
    "# FORCE_PREDICTION_RECORDING = 10\n",
    "results = trainer.eval(e_dataloader, step = trainer.start_epoch + trainer.epochs, temperature = EVAL_TEMPERATURE, repetition_penalty = REPITION_PENALTY)\n",
    "\n",
    "# print results:\n",
    "print(f\"\\n[eval results]:\")\n",
    "print(f\"  [loss]: {results['loss']:.4f}\")\n",
    "print(f\"  [exact match]: {results['exact_match']:.4f}\")\n",
    "print(f\"  [char similarity]: {results['char_similarity']:.4f}\")\n",
    "print(f\"  [levenshtein]: {results['levenshtein']:.4f}\")\n",
    "print(f\"  [jaccard]: {results['jaccard']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

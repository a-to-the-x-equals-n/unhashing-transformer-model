{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "qifqfg25mv",
   "metadata": {},
   "source": [
    "# Optimus Prime - MD5 Hash Inversion Training\n",
    "\n",
    "```\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣶⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢰⠀⠀⠀⠀⠀⣤⣤⣤⠀⠀⠀⠀⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡇⠀⣠⡶⢿⡇⢿⣿⡏⢳⣦⠀⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣾⡛⣆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣧⣼⣿⣴⣋⡽⠮⠿⢭⣟⣏⣷⣿⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢻⣧⠘⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡼⣇⣿⡿⠶⣶⣿⣟⡛⣷⣿⢠⠙⣧⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣀⡈⣏⠇⢹⡀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡟⢹⠁⣿⠋⠉⢹⠉⠙⣿⡇⣾⣀⣾⠀⢀⣤⡀⢀⡀⠀⠀⢀⣠⣴⣾⠛⢻⡛⢻⡄⢀⣳⡀⢀⣠⠄⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣾⣷⣾⢀⣿⡇⠀⠸⠀⠀⣿⣧⡽⠿⣟⣺⣭⠴⢿⡏⣩⣷⡾⢛⣭⣴⣿⣇⠘⣿⣷⣿⡛⠉⢻⣟⣷⠄⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠿⢿⣟⣿⣿⡦⣶⣪⡭⠿⣚⣫⣭⣽⣶⡄⠀⢸⡇⣿⡙⣿⣿⣿⣿⣿⣿⣆⠹⣿⣿⣷⡀⠀⢿⡉⠁⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣀⣀⣤⣶⣿⠿⠛⣉⣭⣶⣾⣿⠿⠟⠛⠉⠉⢻⠀⢸⣷⣿⣇⢻⡿⣿⣿⣿⣿⠟⠀⠹⣿⣿⠃⠀⠘⣷⡀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣤⣦⣼⣿⠿⠛⣋⡁⣼⢠⣿⡿⠛⠉⠁⠀⠀⢀⡀⢀⣴⣾⠀⢸⣿⡇⢻⡄⠙⠿⠻⠛⠁⠀⢀⣠⣽⣿⣇⡀⠀⠸⣧⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⣾⠿⣛⣭⣴⡾⠟⠛⣧⣿⢸⡿⠀⠀⠀⠀⣰⣿⣿⣷⣾⣿⣿⠀⢸⡏⣇⢸⣷⡀⠀⢀⣠⣴⣾⠿⠛⣿⢻⣿⣹⡀⠀⢻⣆⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣴⡟⣦⠀⠀⠀⢀⡿⣵⡿⠛⠉⣡⣶⣤⣄⣿⣯⢸⣇⠀⠀⢠⣾⣿⡿⣿⣿⣿⣿⡿⠀⢸⡇⢻⡼⣿⣷⣶⠿⠛⠉⠀⠀⠀⠸⡇⣿⣿⣧⠀⠘⣿⡀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⡇⢹⠀⢀⣠⣼⣿⣿⠀⢀⣼⣿⣿⣿⣿⡇⣿⢸⣿⣀⣀⣿⡿⠿⠶⠚⠛⠉⠉⠀⠀⢸⡇⠀⢻⣾⣝⣿⡆⠀⢀⣠⡴⠖⠛⢻⡾⣿⣿⣆⠀⢹⡇⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣇⣼⡾⠟⠋⣿⢻⣇⣤⣌⠻⢿⣿⣿⣿⠃⢿⠀⠉⠉⠁⠀⠀⠀⣀⣤⡤⠶⠶⠒⠚⣻⣷⣄⠈⣿⣿⣿⣿⡞⠉⠀⠀⠀⠀⠀⣿⢿⣿⣾⣋⣽⠇⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣹⠏⠀⠀⠀⣿⢿⣿⣿⣯⡴⠾⠛⢋⣡⠶⠛⠛⠋⣉⣉⣉⣙⢻⣿⠀⠀⠀⠀⠀⢠⡟⠀⠈⠻⢦⣈⣿⣿⣧⠀⠀⢀⣠⣴⡾⢿⣿⣿⣿⣿⣿⡀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⡟⣿⡟⠀⠀⠀⣿⠈⠋⠉⢀⣠⠴⣛⣩⣤⣶⣞⣭⣿⢿⣿⣿⣻⣼⣿⣆⣀⣤⣤⣴⣿⣄⣠⣶⣦⣀⣙⣿⣿⣿⡶⣿⠟⠋⣁⣶⠟⢻⣽⣿⣿⣿⠇⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⢠⣿⣇⠀⠀⠀⢹⣠⡴⠖⢻⣷⢫⣿⣿⣿⣯⣿⣟⣿⣿⣭⣽⣿⡿⣿⣿⣿⠿⠿⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⣿⠋⠉⣿⠀⢸⣿⣿⣿⣿⣷⡀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣼⣿⣿⣤⣴⣾⢿⡅⠀⣀⣾⢿⣿⣿⣿⣿⣿⣿⡿⣿⣷⣿⣿⣿⡇⣿⣿⡇⠀⠀⢸⣿⣿⡟⢿⣿⣿⣿⣿⣿⣣⣿⠁⣿⣀⣤⡿⠀⢀⣿⣿⣿⣿⣿⡇⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡇⠻⣿⠛⠉⠀⠈⣿⠛⢽⣿⢻⣿⣿⢿⣿⣿⣿⡇⣿⠿⣶⣶⣚⣧⣿⣿⡇⠀⠀⣸⣿⣿⣿⣄⣈⢿⣿⢿⣷⣿⣿⠀⠉⠉⠀⠀⠀⠘⡇⣿⣿⣿⣿⡇⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡇⡀⣷⡆⠀⠀⠀⠸⣧⣻⣿⢸⣿⣿⡿⢿⣾⣻⡇⣿⣿⣿⣿⣿⣿⣿⠿⠷⠾⠛⠛⠿⢿⣿⣿⣿⣄⣿⠿⠋⢸⣿⠀⠀⠀⠀⠀⠀⠀⡇⣿⣿⣿⣿⣿⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣷⡇⣿⡇⠀⠀⠀⠀⣿⣿⣿⡾⢿⣿⣿⣿⣿⡶⠷⠾⠛⠛⠉⠁⢀⣠⠤⠴⠒⡆⢠⠀⢰⡉⠻⣿⣽⡏⠀⠀⢸⡇⠀⠀⠀⠀⠀⠀⠀⡇⣿⡿⣿⣿⣿⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣧⣿⠿⢀⣀⣤⣴⣿⣿⣿⡷⠾⠛⠋⠉⢀⣀⣠⠤⠴⠒⠻⡆⢸⠀⠀⢀⡠⠇⠸⡄⠈⣇⠀⠈⡻⢦⡀⠀⢸⡇⠀⠀⠀⠀⠀⠀⠀⡇⣿⣧⡘⠿⢻⡆\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠻⣆⣿⣿⣿⣿⣿⡿⠛⣉⣀⡀⣠⠴⠒⠋⠉⠁⠀⠀⠀⠀⠀⡇⢸⣠⠴⣫⡄⠀⠀⡇⠀⢹⠀⠀⣿⠦⢿⡀⢸⡇⠀⠀⣀⣤⣤⣿⠀⡇⣿⣿⣿⣆⢸⡇\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣿⢿⡟⣽⣿⠀⣏⠁⠀⡇⡟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣇⠀⡖⣻⠋⠀⠀⠈⢻⠀⢈⡇⠀⠸⡄⠘⣧⢸⡇⠀⢸⣷⣾⣿⠏⠀⡇⣿⣿⣿⣿⢸⡇\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣾⠏⠛⠋⢡⣿⠀⠸⣿⣟⡃⣇⠀⠀⠀⠀⠀⣀⣠⡤⠶⠒⠋⠀⠛⠁⠀⣀⣤⣶⣿⣿⣿⣿⣷⣤⡈⠁⢻⡞⣿⠀⠈⠻⣴⠏⠀⠀⠿⢹⣿⣎⢻⣿⡇\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣾⡟⠀⠀⢀⡿⣿⠀⠀⠈⠳⡇⠻⠤⠶⠚⠋⠉⠁⠀⠀⠀⠀⠀⣀⣤⣶⣿⣿⣿⣿⣿⠿⠛⠻⣿⣿⣿⣷⣜⣷⣿⠀⠀⢀⣀⣤⣤⣶⣾⣶⣿⣿⠃⢸⡇\n",
    "⠀⠀⠀⠀⠀⠀⣀⣤⡶⠶⠖⠚⢛⠛⠳⢶⣼⡟⠀⠀⢀⣼⣹⣿⢀⠀⠀⠀⠀⡀⠀⠀⠀⠀⠀⢀⣀⣠⡤⢤⣾⣿⣿⣿⡿⠿⠛⠉⠹⡇⠀⠀⣿⣿⣟⢿⣿⣿⠹⣶⣿⡿⠛⠻⣏⠀⠉⠉⡛⣿⡿⣾⡇\n",
    "⠀⠀⠀⢀⣴⠞⠋⢰⡇⢰⣿⢻⢻⢻⢶⣦⠙⣷⡀⠀⣸⢧⠟⢿⣿⣿⣿⣷⣶⣶⣤⣴⣲⡾⠿⠟⠒⠒⠛⡇⠙⣿⠉⠀⢧⠀⠀⠀⠀⣧⠀⠀⢸⣿⣿⡎⣿⠁⢀⣼⣏⢀⣠⣤⣸⣶⠀⠀⣿⣿⣿⠛⠁\n",
    "⠀⠀⠀⣾⠃⠀⣠⡬⣤⣼⣛⠾⣼⣞⡾⡟⠀⠘⣧⣠⣏⡞⠀⠈⠻⣿⡏⢹⡟⠛⠻⣿⠁⠀⠀⠀⠀⠀⠀⣇⠀⣿⠀⠀⢸⡄⠀⠀⠀⢸⠀⠀⠘⣿⣿⣇⣿⣴⡞⢣⣽⣿⣿⣿⣿⣿⠀⠀⣿⣿⡟⠀⠀\n",
    "⠀⠀⠀⣿⡶⣿⣿⣸⣿⣿⣿⠿⠷⠾⢽⣅⡲⠶⢻⣿⣼⢁⣠⣤⣶⣿⣿⠘⡇⠀⠀⢻⡆⠀⠀⠀⠀⠀⢀⣸⡀⢹⡇⠀⠈⡇⠀⠀⠀⠈⡇⠀⠀⢿⣿⣿⢹⣿⣤⣿⣿⣿⣿⡿⢿⣟⡀⠀⣿⣿⡇⠀⠀\n",
    "⠀⠀⠀⠈⠛⠿⢯⣜⣿⠏⠀⠀⠀⢀⡿⣨⣿⣶⣤⣿⣷⣯⣿⣿⣿⣿⣿⠀⡇⠀⠀⠐⡿⣦⣰⣒⣶⣿⣿⣿⣷⣾⣇⠀⠀⢻⠀⠀⠀⠀⢷⠀⠀⢸⣿⣿⣾⣿⣸⣿⡏⢠⠟⣠⣿⣿⣿⣦⡈⢹⡇⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⢸⡟⣾⠄⠀⠀⣸⡇⣿⣿⣿⠟⠋⠛⢿⣿⣿⣿⣿⣿⡄⢻⠀⠀⠀⡇⠈⠙⣿⣿⣿⣿⣿⣿⣿⣿⠀⠀⢸⡆⠀⠀⠀⢸⡄⠀⠀⣿⣿⣇⣿⠛⠛⠻⣿⣺⣿⣿⣿⣿⣿⣿⡿⠃⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⣼⢧⡇⠀⠀⠀⣿⢸⣿⣿⡿⢦⣴⣿⣿⣷⡿⣿⡿⣿⡇⢸⡄⠀⠀⢹⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⡆⠀⠀⣇⠀⠀⠀⠀⣇⠀⠀⢸⣿⣟⢿⡀⠀⠀⠈⠉⠀⠉⠉⠉⠁⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⣿⣨⡧⠤⠤⢤⣇⡾⣿⣿⣠⣿⣿⣿⣿⣿⣿⣽⣿⣿⣷⠀⣇⠀⠀⢸⠀⠀⢸⢻⣿⣿⣿⣿⡇⣿⣿⠀⠀⢹⡄⠀⠀⢀⣸⠀⠀⠸⣿⣿⣼⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⢀⡿⣧⣤⠶⠦⣼⣿⣿⣿⡏⠈⣿⣿⢿⣿⣿⣿⣏⠉⢹⣿⡀⢻⠀⠀⠘⡇⠀⠸⡄⠙⢿⣿⣿⠇⣿⣿⡄⠀⠈⠓⠒⠋⠉⠀⠀⠀⠀⢿⠹⣯⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⣸⣿⢃⡏⠀⠀⢻⣿⣿⣽⣿⣦⠘⣿⣿⣿⣿⣿⢻⣿⣾⣿⡇⠘⡇⠀⠀⣇⠀⠀⣇⠀⠀⠙⢿⡇⣿⢸⣧⠀⠀⠀⠀⡴⠒⢶⠀⠀⠀⠘⣆⠀⢻⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⡿⡅⣸⢁⣄⡄⣾⣿⢿⣿⠿⣿⣿⢻⣿⣿⣟⣿⣸⣻⡿⣿⣧⠀⠙⠒⠛⠛⠀⠀⢿⣿⣄⠀⠀⠀⣿⠈⣿⡄⠀⠀⠀⡇⠀⠘⡇⠀⠀⠀⢿⣦⢸⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⢸⣧⡇⣿⣼⣿⠃⣿⣿⣾⣿⣷⣤⡿⠿⢿⣿⣿⣇⣿⡟⠋⠀⣿⡀⠀⣴⠲⡆⠀⠀⠸⣿⣿⣦⠀⠀⢸⡀⢹⣧⠀⠀⠀⣇⠀⠀⢹⠀⠀⠀⠸⣿⡟⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀  ⢽⡿⣷⠏⠛⠿⢠⣿⣿⣿⣿⢿⣯⡇⠀⠀⠈⠁⠀⠀⠀⠀⠀⢸⣇⠀⢻⠀⢳⠀⠀⠀⣿⣿⣿⣷⣾⢸⡇⠈⣿⡀⠀⠀⢸⠀⠀⠈⡇⠀⠀⢀⣿⣿⣷⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "            ____        __  _                         ____       _              ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "           / __ \\____  / /_(_)___ ___  __  _______   / __ \\_____(_)___ ___  ___ ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "          / / / / __ \\/ __/ / __ `__ \\/ / / / ___/  / /_/ / ___/ / __ `__ \\/ _ \\⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "         / /_/ / /_/ / /_/ / / / / / / /_/ (__  )  / ____/ /  / / / / / / /  __/⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "         \\____/ .___/\\__/_/_/ /_/ /_/\\__,_/____/  /_/   /_/  /_/_/ /_/ /_/\\___/ ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "             /_/                                                                 ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "```\n",
    "\n",
    "## Overview\n",
    "This notebook trains the **OptimusPrime** transformer model to learn mappings from MD5 hash digests to plaintext passwords.\n",
    "\n",
    "- **Model**: Transformer encoder-decoder architecture\n",
    "- **Task**: Sequence-to-sequence learning (hash → password)\n",
    "- **Dataset**: 1M hash-password pairs\n",
    "- **Features**: TensorBoard logging, checkpoint saving/loading, evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sbdkvic8jos",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "\n",
    "Import all necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b54b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from model import OptimusPrime\n",
    "from data import Bumblebee, collate_batch, ALLOWED_PW_CHARS as PW_VOCAB, PAD_ID, SOS_ID, EOS_ID\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emfbm9qg5iu",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Set device, paths, training hyperparameters, and model architecture parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xjlz4r9te6h",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "path = Path.cwd().parent / 'data' / 'training' / '1M_train.tsv'\n",
    "\n",
    "# training hyperparameters\n",
    "epochs = 10\n",
    "batch_size = 1024\n",
    "lr = 1e-4\n",
    "\n",
    "# model architecture\n",
    "model_config = {\n",
    "    'vocab_size': 257,\n",
    "    'pw_vocab_size': len(PW_VOCAB),\n",
    "    'pad_id': PAD_ID,\n",
    "    'sos_id': SOS_ID,\n",
    "    'eos_id': EOS_ID,\n",
    "    'd_model': 256,\n",
    "    'n_heads': 8,\n",
    "    'num_layers': 4,\n",
    "    'ff_dim': 512,\n",
    "    'dropout': 0.1\n",
    "}\n",
    "\n",
    "print(f'Device: {device}')\n",
    "print(f'Data: {path}')\n",
    "print(f'Model config: {model_config}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w34yj38jzlk",
   "metadata": {},
   "source": [
    "## 3. Dataset & DataLoader\n",
    "\n",
    "Load the hash-password dataset and create a batched DataLoader with custom collate function for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sbdtsu44zf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and dataloader\n",
    "dataset = Bumblebee(path)\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    collate_fn = collate_batch\n",
    ")\n",
    "\n",
    "print(f'Dataset size: {len(dataset):,} samples')\n",
    "print(f'Batches per epoch: {len(dataloader):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iwoizk3l9g",
   "metadata": {},
   "source": [
    "## 4. Model Creation\n",
    "\n",
    "Initialize the OptimusPrime transformer encoder-decoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p2a9iljec9p",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = OptimusPrime(**model_config)\n",
    "\n",
    "# count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'Model: OptimusPrime')\n",
    "print(f'Total parameters: {total_params:,}')\n",
    "print(f'Trainable parameters: {trainable_params:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cgtrzfsmh",
   "metadata": {},
   "source": [
    "## 5. Optimizer\n",
    "\n",
    "Configure the Adam optimizer with the specified learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881v8jhiqq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer\n",
    "optimizer = Adam(model.parameters(), lr = lr)\n",
    "\n",
    "print(f'Optimizer: Adam')\n",
    "print(f'Learning rate: {lr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psefc52rj4",
   "metadata": {},
   "source": [
    "## 6. Trainer Setup\n",
    "\n",
    "Create the Trainer instance with all components and initialize TensorBoard logging.\n",
    "\n",
    ">**Note**: Set `save = False` and `load = False` for testing without checkpoint I/O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9n1uqtuu54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create trainer\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    dataloader = dataloader,\n",
    "    device = device,\n",
    "    epochs = epochs,\n",
    "    checkpoint_dir = Path('checkpoints'),\n",
    "    checkpoint_interval = 1,\n",
    "    logs = 'runs/optimus',\n",
    "    save = True,\n",
    "    load = True\n",
    ")\n",
    "\n",
    "# setup trainer\n",
    "trainer.setup()\n",
    "\n",
    "# load checkpoint if exists (skipped if load = False)\n",
    "trainer.load_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uew222q9yi",
   "metadata": {},
   "source": [
    "## 7. Training\n",
    "\n",
    "Run the full training loop with gradient tracking, TensorBoard logging, and checkpoint saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mkk6ugdczyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8vs9tp4nv8e",
   "metadata": {},
   "source": [
    "## 8. Evaluation\n",
    "\n",
    "Evaluate the trained model on a held-out test set with multiple similarity metrics:\n",
    "- **Exact Match**: Perfect character-by-character match\n",
    "- **Char Similarity**: Positional character matching\n",
    "- **Levenshtein**: Normalized edit distance\n",
    "- **Jaccard**: Character set overlap\n",
    "\n",
    "Results are logged to TensorBoard under the `Eval/` namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lso8lej4t",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "eval_dataset = Bumblebee(Path.cwd().parent / 'data' / 'eval' / '1K_eval.tsv')\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size = 128, shuffle = False, collate_fn = collate_batch, drop_last = False)\n",
    "\n",
    "# evaluate without TensorBoard logging (standalone):\n",
    "# results = trainer.eval(eval_dataloader)\n",
    "\n",
    "# evaluate WITH TensorBoard logging (pass current epoch/step):\n",
    "results = trainer.eval(eval_dataloader, step = trainer.start_epoch + trainer.epochs)\n",
    "\n",
    "# print results:\n",
    "print(f\"\\nEval Results:\")\n",
    "print(f\"  Loss: {results['loss']:.4f}\")\n",
    "print(f\"  Exact Match: {results['exact_match']:.4f}\")\n",
    "print(f\"  Char Similarity: {results['char_similarity']:.4f}\")\n",
    "print(f\"  Levenshtein: {results['levenshtein']:.4f}\")\n",
    "print(f\"  Jaccard: {results['jaccard']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j8gvuhyikq",
   "metadata": {},
   "source": [
    "## 9. Cleanup\n",
    "\n",
    "Close TensorBoard writer and display training summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pksq233fyiq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup and display summary\n",
    "trainer.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
